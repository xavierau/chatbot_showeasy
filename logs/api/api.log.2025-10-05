{"request_id": "2b41c09a", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:16:04.799863Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:16:04.811780Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 0, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:16:04.812577Z"}
{"request_id": "2b41c09a", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 23.51, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:16:04.814023Z"}
{"request_id": "de435d9c", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:16:08.240982Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:16:08.243827Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:16:08.444480Z"}
{"event": "Retrying request to /chat/completions in 0.462429 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:09.932462Z"}
{"event": "Retrying request to /chat/completions in 0.870117 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:10.400757Z"}
{"event": "Retrying request to /chat/completions in 1.696245 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:11.278069Z"}
{"event": "Retrying request to /chat/completions in 0.408286 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:13.008484Z"}
{"event": "Retrying request to /chat/completions in 0.861773 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:13.419089Z"}
{"event": "Retrying request to /chat/completions in 1.888674 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:14.291114Z"}
{"event": "Retrying request to /chat/completions in 0.470863 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:17.253376Z"}
{"event": "Retrying request to /chat/completions in 0.957441 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:17.737508Z"}
{"event": "Retrying request to /chat/completions in 1.753393 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:18.708034Z"}
{"event": "Retrying request to /chat/completions in 0.377116 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:22.514193Z"}
{"event": "Retrying request to /chat/completions in 0.776167 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:22.895204Z"}
{"event": "Retrying request to /chat/completions in 1.528950 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:23.681194Z"}
{"event": "Retrying request to /chat/completions in 0.401163 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:25.261864Z"}
{"event": "Retrying request to /chat/completions in 0.958847 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:25.665683Z"}
{"event": "Retrying request to /chat/completions in 1.837771 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:26.636054Z"}
{"event": "Retrying request to /chat/completions in 0.475250 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:28.490697Z"}
{"event": "Retrying request to /chat/completions in 0.944606 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:28.973675Z"}
{"event": "Retrying request to /chat/completions in 1.937100 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:29.923469Z"}
{"event": "Retrying request to /chat/completions in 0.489838 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:32.894560Z"}
{"event": "Retrying request to /chat/completions in 0.841679 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:33.391804Z"}
{"event": "Retrying request to /chat/completions in 1.795841 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:34.242220Z"}
{"event": "Retrying request to /chat/completions in 0.427219 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:38.070063Z"}
{"event": "Retrying request to /chat/completions in 0.851546 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:38.504331Z"}
{"event": "Retrying request to /chat/completions in 1.733575 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:39.366064Z"}
{"event": "Retrying request to /chat/completions in 0.494320 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:41.154988Z"}
{"event": "Retrying request to /chat/completions in 0.871236 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:41.657068Z"}
{"event": "Retrying request to /chat/completions in 1.680000 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:42.534838Z"}
{"event": "Retrying request to /chat/completions in 0.386823 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:44.226629Z"}
{"event": "Retrying request to /chat/completions in 0.769669 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:44.624514Z"}
{"event": "Retrying request to /chat/completions in 1.646695 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:45.405446Z"}
{"event": "Retrying request to /chat/completions in 0.473970 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:48.076945Z"}
{"event": "Retrying request to /chat/completions in 0.891347 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:48.561849Z"}
{"event": "Retrying request to /chat/completions in 1.500399 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:49.460634Z"}
{"event": "Retrying request to /chat/completions in 0.483565 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:52.983328Z"}
{"event": "Retrying request to /chat/completions in 0.819696 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:53.470990Z"}
{"event": "Retrying request to /chat/completions in 1.719002 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:16:54.302012Z"}
{"request_id": "de435d9c", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 53, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 47851.99, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:16:56.092212Z"}
{"request_id": "367eef4b", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:18:12.910135Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:18:12.914111Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 0, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:18:12.914322Z"}
{"request_id": "367eef4b", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 5.28, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:18:12.914780Z"}
{"request_id": "3f751f78", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:18:15.300587Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:18:15.304762Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:18:15.535296Z"}
{"event": "Retrying request to /chat/completions in 0.455697 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:16.005523Z"}
{"event": "Retrying request to /chat/completions in 0.998484 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:16.464775Z"}
{"event": "Retrying request to /chat/completions in 1.609122 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:17.468333Z"}
{"event": "Retrying request to /chat/completions in 0.441141 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:19.117224Z"}
{"event": "Retrying request to /chat/completions in 0.833826 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:19.564157Z"}
{"event": "Retrying request to /chat/completions in 1.794127 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:20.402795Z"}
{"event": "Retrying request to /chat/completions in 0.417312 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:23.260188Z"}
{"event": "Retrying request to /chat/completions in 0.796300 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:23.686317Z"}
{"event": "Retrying request to /chat/completions in 1.644411 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:24.504214Z"}
{"event": "Retrying request to /chat/completions in 0.486200 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:28.192700Z"}
{"event": "Retrying request to /chat/completions in 0.864872 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:28.686856Z"}
{"event": "Retrying request to /chat/completions in 1.809082 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:29.563257Z"}
{"event": "Retrying request to /chat/completions in 0.437097 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:31.436314Z"}
{"event": "Retrying request to /chat/completions in 0.786771 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:31.877944Z"}
{"event": "Retrying request to /chat/completions in 1.742089 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:32.670896Z"}
{"event": "Retrying request to /chat/completions in 0.424675 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:34.422466Z"}
{"event": "Retrying request to /chat/completions in 0.840285 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:34.856784Z"}
{"event": "Retrying request to /chat/completions in 1.718331 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:35.704872Z"}
{"event": "Retrying request to /chat/completions in 0.498419 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:38.458071Z"}
{"event": "Retrying request to /chat/completions in 0.808694 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:38.964818Z"}
{"event": "Retrying request to /chat/completions in 1.683480 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:39.781341Z"}
{"event": "Retrying request to /chat/completions in 0.473933 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:43.522469Z"}
{"event": "Retrying request to /chat/completions in 0.840874 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:44.005614Z"}
{"event": "Retrying request to /chat/completions in 1.674433 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:44.850716Z"}
{"event": "Retrying request to /chat/completions in 0.454923 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:46.570222Z"}
{"event": "Retrying request to /chat/completions in 0.758534 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:47.033237Z"}
{"event": "Retrying request to /chat/completions in 1.500863 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:47.801103Z"}
{"event": "Retrying request to /chat/completions in 0.393629 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:49.330441Z"}
{"event": "Retrying request to /chat/completions in 0.830360 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:49.729754Z"}
{"event": "Retrying request to /chat/completions in 1.556446 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:50.566022Z"}
{"event": "Retrying request to /chat/completions in 0.392249 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:53.161456Z"}
{"event": "Retrying request to /chat/completions in 0.849566 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:53.560392Z"}
{"event": "Retrying request to /chat/completions in 1.941602 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:54.418454Z"}
{"event": "Retrying request to /chat/completions in 0.467472 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:58.392713Z"}
{"event": "Retrying request to /chat/completions in 0.931946 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:58.867559Z"}
{"event": "Retrying request to /chat/completions in 1.830076 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:18:59.808615Z"}
{"request_id": "ea9dd19b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:20:58.110536Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:20:58.115703Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:20:58.287457Z"}
{"event": "Retrying request to /chat/completions in 0.399428 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:20:58.809248Z"}
{"event": "Retrying request to /chat/completions in 0.915670 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:20:59.218064Z"}
{"event": "Retrying request to /chat/completions in 1.858964 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:00.147395Z"}
{"event": "Retrying request to /chat/completions in 0.436206 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:02.034333Z"}
{"event": "Retrying request to /chat/completions in 0.986572 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:02.477962Z"}
{"event": "Retrying request to /chat/completions in 1.536268 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:03.478538Z"}
{"event": "Retrying request to /chat/completions in 0.491751 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:06.094887Z"}
{"event": "Retrying request to /chat/completions in 0.753862 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:06.591590Z"}
{"event": "Retrying request to /chat/completions in 1.636684 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:07.358859Z"}
{"event": "Retrying request to /chat/completions in 0.434322 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:11.034972Z"}
{"event": "Retrying request to /chat/completions in 0.812701 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:11.473489Z"}
{"event": "Retrying request to /chat/completions in 1.540744 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:12.294226Z"}
{"event": "Retrying request to /chat/completions in 0.448001 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:13.885159Z"}
{"event": "Retrying request to /chat/completions in 0.956506 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:14.340709Z"}
{"event": "Retrying request to /chat/completions in 1.725321 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:15.304410Z"}
{"event": "Retrying request to /chat/completions in 0.393886 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:17.042274Z"}
{"event": "Retrying request to /chat/completions in 0.911755 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:17.446005Z"}
{"event": "Retrying request to /chat/completions in 1.555793 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:18.369674Z"}
{"event": "Retrying request to /chat/completions in 0.453472 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:20.961439Z"}
{"event": "Retrying request to /chat/completions in 0.758942 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:21.428170Z"}
{"event": "Retrying request to /chat/completions in 1.913555 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:22.195740Z"}
{"event": "Retrying request to /chat/completions in 0.396200 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:26.139775Z"}
{"event": "Retrying request to /chat/completions in 0.859005 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:26.542091Z"}
{"event": "Retrying request to /chat/completions in 1.866069 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:27.404394Z"}
{"event": "Retrying request to /chat/completions in 0.458406 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:29.312710Z"}
{"event": "Retrying request to /chat/completions in 0.940089 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:29.777834Z"}
{"event": "Retrying request to /chat/completions in 1.870504 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:30.724368Z"}
{"event": "Retrying request to /chat/completions in 0.494597 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:32.608230Z"}
{"event": "Retrying request to /chat/completions in 0.901835 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:33.106498Z"}
{"event": "Retrying request to /chat/completions in 1.789599 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:34.020848Z"}
{"event": "Retrying request to /chat/completions in 0.475722 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:36.840327Z"}
{"event": "Retrying request to /chat/completions in 0.869190 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:21:37.318389Z"}
{"request_id": "20880d9e", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:23:35.916052Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:23:35.919764Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:23:36.121227Z"}
{"request_id": "20880d9e", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 53, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 424, in exception_type\n    raise AuthenticationError(\n    ...<5 lines>...\n    )\nlitellm.exceptions.AuthenticationError: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable", "duration_ms": 9991.39, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:23:45.906768Z"}
{"request_id": "45995532", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:24:26.118403Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:24:26.121352Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:24:26.464554Z"}
{"event": "Retrying request to /chat/completions in 0.416219 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:26.923194Z"}
{"event": "Retrying request to /chat/completions in 0.841889 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:27.345937Z"}
{"event": "Retrying request to /chat/completions in 1.976874 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:28.194869Z"}
{"event": "Retrying request to /chat/completions in 0.397388 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:33.322043Z"}
{"event": "Retrying request to /chat/completions in 0.809245 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:33.729883Z"}
{"event": "Retrying request to /chat/completions in 1.875820 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:34.546732Z"}
{"event": "Retrying request to /chat/completions in 0.387976 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:39.512265Z"}
{"event": "Retrying request to /chat/completions in 0.987583 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:39.905295Z"}
{"event": "Retrying request to /chat/completions in 1.967799 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:24:40.902010Z"}
{"request_id": "45995532", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 53, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 502, in exception_type\n    raise InternalServerError(\n    ...<5 lines>...\n    )\nlitellm.exceptions.InternalServerError: litellm.InternalServerError: InternalServerError: OpenAIException - Connection error.", "duration_ms": 19888.69, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:24:46.003187Z"}
{"request_id": "bbf48ad7", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:36:40.849895Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:36:40.859004Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:36:41.540148Z"}
{"event": "Retrying request to /chat/completions in 0.409217 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:42.049715Z"}
{"event": "Retrying request to /chat/completions in 0.850676 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:42.461131Z"}
{"event": "Retrying request to /chat/completions in 1.699283 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:43.319495Z"}
{"event": "Retrying request to /chat/completions in 0.482662 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:45.038613Z"}
{"event": "Retrying request to /chat/completions in 0.992019 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:45.523740Z"}
{"event": "Retrying request to /chat/completions in 1.983600 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:46.524398Z"}
{"event": "Retrying request to /chat/completions in 0.489326 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:49.549609Z"}
{"event": "Retrying request to /chat/completions in 0.975276 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:50.048459Z"}
{"event": "Retrying request to /chat/completions in 1.557313 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:51.042765Z"}
{"event": "Retrying request to /chat/completions in 0.383624 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:54.630224Z"}
{"event": "Retrying request to /chat/completions in 0.774041 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:55.024846Z"}
{"event": "Retrying request to /chat/completions in 1.675210 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:55.803672Z"}
{"event": "Retrying request to /chat/completions in 0.464624 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:57.537221Z"}
{"event": "Retrying request to /chat/completions in 0.999422 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:58.007204Z"}
{"event": "Retrying request to /chat/completions in 1.836952 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:36:59.015835Z"}
{"event": "Retrying request to /chat/completions in 0.438920 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:00.881677Z"}
{"event": "Retrying request to /chat/completions in 0.941100 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:01.332836Z"}
{"event": "Retrying request to /chat/completions in 1.927604 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:02.286496Z"}
{"event": "Retrying request to /chat/completions in 0.479410 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:05.284125Z"}
{"event": "Retrying request to /chat/completions in 0.833732 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:05.770880Z"}
{"event": "Retrying request to /chat/completions in 1.780621 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:06.610272Z"}
{"event": "Retrying request to /chat/completions in 0.396263 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:10.426651Z"}
{"event": "Retrying request to /chat/completions in 0.984459 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:10.829570Z"}
{"event": "Retrying request to /chat/completions in 1.530177 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:11.824315Z"}
{"event": "Retrying request to /chat/completions in 0.496481 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:13.414265Z"}
{"event": "Retrying request to /chat/completions in 0.969600 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:13.919541Z"}
{"event": "Retrying request to /chat/completions in 1.951171 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:14.899554Z"}
{"event": "Retrying request to /chat/completions in 0.486552 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:16.880918Z"}
{"event": "Retrying request to /chat/completions in 0.868080 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:17.378089Z"}
{"event": "Retrying request to /chat/completions in 1.859768 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:18.254160Z"}
{"event": "Retrying request to /chat/completions in 0.471744 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:21.141252Z"}
{"event": "Retrying request to /chat/completions in 0.780221 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:21.619521Z"}
{"event": "Retrying request to /chat/completions in 1.619739 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:22.407338Z"}
{"event": "Retrying request to /chat/completions in 0.397573 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:26.056871Z"}
{"event": "Retrying request to /chat/completions in 0.957847 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:26.457587Z"}
{"event": "Retrying request to /chat/completions in 1.946823 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:37:27.424541Z"}
{"request_id": "bbf48ad7", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 53, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 48619.36, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:37:29.468809Z"}
{"request_id": "d41ab379", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:38:29.709558Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:38:29.715606Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:38:30.339994Z"}
{"event": "Retrying request to /chat/completions in 0.409221 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:30.872434Z"}
{"event": "Retrying request to /chat/completions in 0.997499 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:31.289941Z"}
{"event": "Retrying request to /chat/completions in 1.515529 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:32.295181Z"}
{"event": "Retrying request to /chat/completions in 0.486144 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:33.834843Z"}
{"event": "Retrying request to /chat/completions in 0.789495 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:34.329455Z"}
{"event": "Retrying request to /chat/completions in 1.933379 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:35.128488Z"}
{"event": "Retrying request to /chat/completions in 0.427273 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:38.127678Z"}
{"event": "Retrying request to /chat/completions in 0.895627 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:38.562501Z"}
{"event": "Retrying request to /chat/completions in 1.688415 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:39.468670Z"}
{"event": "Retrying request to /chat/completions in 0.495349 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:43.180738Z"}
{"event": "Retrying request to /chat/completions in 0.781481 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:43.681604Z"}
{"event": "Retrying request to /chat/completions in 1.636591 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:44.472587Z"}
{"event": "Retrying request to /chat/completions in 0.388819 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:46.173506Z"}
{"event": "Retrying request to /chat/completions in 0.840286 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:46.574389Z"}
{"event": "Retrying request to /chat/completions in 1.713756 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:47.420665Z"}
{"event": "Retrying request to /chat/completions in 0.412429 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:49.150747Z"}
{"event": "Retrying request to /chat/completions in 0.819083 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:49.571408Z"}
{"event": "Retrying request to /chat/completions in 1.604283 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:50.399678Z"}
{"event": "Retrying request to /chat/completions in 0.420227 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:53.031631Z"}
{"event": "Retrying request to /chat/completions in 0.995042 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:53.455732Z"}
{"event": "Retrying request to /chat/completions in 1.976102 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:54.458368Z"}
{"event": "Retrying request to /chat/completions in 0.385345 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:58.470575Z"}
{"event": "Retrying request to /chat/completions in 0.982262 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:58.865446Z"}
{"event": "Retrying request to /chat/completions in 1.866651 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:38:59.856804Z"}
{"event": "Retrying request to /chat/completions in 0.461713 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:01.770589Z"}
{"event": "Retrying request to /chat/completions in 0.959533 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:02.236975Z"}
{"event": "Retrying request to /chat/completions in 1.539606 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:03.202672Z"}
{"event": "Retrying request to /chat/completions in 0.397765 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:04.756483Z"}
{"event": "Retrying request to /chat/completions in 0.775922 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:05.162034Z"}
{"event": "Retrying request to /chat/completions in 1.659787 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:05.947210Z"}
{"event": "Retrying request to /chat/completions in 0.474381 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:08.652313Z"}
{"event": "Retrying request to /chat/completions in 0.819678 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:09.133919Z"}
{"event": "Retrying request to /chat/completions in 1.999914 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:09.962233Z"}
{"event": "Retrying request to /chat/completions in 0.485870 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:13.989617Z"}
{"event": "Retrying request to /chat/completions in 0.795554 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:14.481146Z"}
{"event": "Retrying request to /chat/completions in 1.500243 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:39:15.281052Z"}
{"request_id": "d41ab379", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 53, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 47169.52, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:39:16.878379Z"}
{"request_id": "5bcc42a7", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:40:43.357051Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:40:43.359451Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:40:43.576890Z"}
{"event": "Retrying request to /chat/completions in 0.482644 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:44.189392Z"}
{"event": "Retrying request to /chat/completions in 0.830266 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:44.678776Z"}
{"event": "Retrying request to /chat/completions in 1.828296 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:45.514606Z"}
{"event": "Retrying request to /chat/completions in 0.412205 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:47.362621Z"}
{"event": "Retrying request to /chat/completions in 0.836528 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:47.779813Z"}
{"event": "Retrying request to /chat/completions in 1.735022 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:48.621275Z"}
{"event": "Retrying request to /chat/completions in 0.488972 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:51.399101Z"}
{"event": "Retrying request to /chat/completions in 0.886471 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:51.896142Z"}
{"event": "Retrying request to /chat/completions in 1.969898 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:52.794424Z"}
{"event": "Retrying request to /chat/completions in 0.429973 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:56.796607Z"}
{"event": "Retrying request to /chat/completions in 0.835702 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:57.235364Z"}
{"event": "Retrying request to /chat/completions in 1.890583 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:40:58.079832Z"}
{"event": "Retrying request to /chat/completions in 0.496728 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:00.047355Z"}
{"event": "Retrying request to /chat/completions in 0.903806 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:00.548793Z"}
{"event": "Retrying request to /chat/completions in 1.771883 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:01.460699Z"}
{"event": "Retrying request to /chat/completions in 0.481587 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:03.243072Z"}
{"event": "Retrying request to /chat/completions in 0.905770 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:03.736909Z"}
{"event": "Retrying request to /chat/completions in 1.680634 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:04.728984Z"}
{"event": "Retrying request to /chat/completions in 0.437349 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:07.463363Z"}
{"event": "Retrying request to /chat/completions in 0.790595 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:07.908157Z"}
{"event": "Retrying request to /chat/completions in 1.680352 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:08.705758Z"}
{"event": "Retrying request to /chat/completions in 0.486019 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:12.546448Z"}
{"event": "Retrying request to /chat/completions in 0.876660 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:13.036336Z"}
{"event": "Retrying request to /chat/completions in 1.967375 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:13.920885Z"}
{"event": "Retrying request to /chat/completions in 0.461594 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:15.971433Z"}
{"event": "Retrying request to /chat/completions in 0.976190 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:16.439837Z"}
{"event": "Retrying request to /chat/completions in 1.758191 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:17.425745Z"}
{"event": "Retrying request to /chat/completions in 0.495129 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:19.195447Z"}
{"event": "Retrying request to /chat/completions in 0.920603 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:19.701288Z"}
{"event": "Retrying request to /chat/completions in 1.505503 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:20.631221Z"}
{"event": "Retrying request to /chat/completions in 0.454985 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:23.168190Z"}
{"event": "Retrying request to /chat/completions in 0.876469 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:23.635334Z"}
{"event": "Retrying request to /chat/completions in 1.529319 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:24.515579Z"}
{"event": "Retrying request to /chat/completions in 0.472290 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:28.101151Z"}
{"event": "Retrying request to /chat/completions in 0.853835 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:28.578362Z"}
{"event": "Retrying request to /chat/completions in 1.907496 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:41:29.436052Z"}
{"request_id": "5bcc42a7", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 53, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 48066.58, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:41:31.423377Z"}
{"request_id": "bd4661e3", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:42:26.745054Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:42:26.764892Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 0, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:42:26.765712Z"}
{"request_id": "bd4661e3", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 24.66, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:42:26.767029Z"}
{"request_id": "3f896881", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:42:29.817546Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:42:29.830466Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:42:30.043491Z"}
{"event": "Retrying request to /chat/completions in 0.412654 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:30.673803Z"}
{"event": "Retrying request to /chat/completions in 0.854030 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:31.104802Z"}
{"event": "Retrying request to /chat/completions in 1.879835 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:31.968964Z"}
{"event": "Retrying request to /chat/completions in 0.405150 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:33.877442Z"}
{"event": "Retrying request to /chat/completions in 0.923228 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:34.285868Z"}
{"event": "Retrying request to /chat/completions in 1.948199 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:35.214974Z"}
{"event": "Retrying request to /chat/completions in 0.423219 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:38.348382Z"}
{"event": "Retrying request to /chat/completions in 0.909554 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:38.780855Z"}
{"event": "Retrying request to /chat/completions in 1.596158 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:39.707400Z"}
{"event": "Retrying request to /chat/completions in 0.487381 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:43.336903Z"}
{"event": "Retrying request to /chat/completions in 0.772961 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:43.826469Z"}
{"event": "Retrying request to /chat/completions in 1.676938 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:44.609088Z"}
{"event": "Retrying request to /chat/completions in 0.402784 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:46.350198Z"}
{"event": "Retrying request to /chat/completions in 0.926046 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:46.759717Z"}
{"event": "Retrying request to /chat/completions in 1.850726 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:47.689968Z"}
{"event": "Retrying request to /chat/completions in 0.498818 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:49.562689Z"}
{"event": "Retrying request to /chat/completions in 0.876870 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:50.077667Z"}
{"event": "Retrying request to /chat/completions in 1.660026 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:50.964502Z"}
{"event": "Retrying request to /chat/completions in 0.391382 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:53.664647Z"}
{"event": "Retrying request to /chat/completions in 0.826198 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:54.063334Z"}
{"event": "Retrying request to /chat/completions in 1.646932 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:54.893893Z"}
{"event": "Retrying request to /chat/completions in 0.404615 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:58.566976Z"}
{"event": "Retrying request to /chat/completions in 0.891961 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:58.974920Z"}
{"event": "Retrying request to /chat/completions in 1.608282 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:42:59.875133Z"}
{"event": "Retrying request to /chat/completions in 0.395158 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:01.572431Z"}
{"event": "Retrying request to /chat/completions in 0.877247 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:01.983075Z"}
{"event": "Retrying request to /chat/completions in 1.741888 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:02.867105Z"}
{"event": "Retrying request to /chat/completions in 0.390768 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:04.687672Z"}
{"event": "Retrying request to /chat/completions in 0.846767 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:05.095362Z"}
{"event": "Retrying request to /chat/completions in 1.764493 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:05.954705Z"}
{"event": "Retrying request to /chat/completions in 0.385240 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:08.853116Z"}
{"event": "Retrying request to /chat/completions in 0.963198 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:09.244736Z"}
{"event": "Retrying request to /chat/completions in 1.977165 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:10.219950Z"}
{"event": "Retrying request to /chat/completions in 0.498508 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:14.231584Z"}
{"event": "Retrying request to /chat/completions in 0.904044 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:14.737730Z"}
{"event": "Retrying request to /chat/completions in 1.646854 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:43:15.656240Z"}
{"request_id": "3f896881", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 53, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 47565.16, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:43:17.381043Z"}
{"request_id": "f05afd40", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:48:57.295640Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:48:57.296785Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:48:57.499942Z"}
{"event": "Retrying request to /chat/completions in 0.474983 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:48:57.890486Z"}
{"event": "Retrying request to /chat/completions in 0.758127 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:48:58.374544Z"}
{"event": "Retrying request to /chat/completions in 1.944553 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:48:59.143759Z"}
{"event": "Retrying request to /chat/completions in 0.400742 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:01.117496Z"}
{"event": "Retrying request to /chat/completions in 0.790376 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:01.524046Z"}
{"event": "Retrying request to /chat/completions in 1.951012 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:02.321589Z"}
{"event": "Retrying request to /chat/completions in 0.486732 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:05.328083Z"}
{"event": "Retrying request to /chat/completions in 0.899476 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:05.829782Z"}
{"event": "Retrying request to /chat/completions in 1.894175 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:06.736660Z"}
{"event": "Retrying request to /chat/completions in 0.481947 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:10.661942Z"}
{"event": "Retrying request to /chat/completions in 0.951667 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:11.151857Z"}
{"event": "Retrying request to /chat/completions in 1.715860 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:12.110628Z"}
{"event": "Retrying request to /chat/completions in 0.463786 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:13.909002Z"}
{"event": "Retrying request to /chat/completions in 0.803165 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:14.380388Z"}
{"event": "Retrying request to /chat/completions in 1.914287 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:15.187128Z"}
{"event": "Retrying request to /chat/completions in 0.485141 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:17.116174Z"}
{"event": "Retrying request to /chat/completions in 0.800806 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:17.609878Z"}
{"event": "Retrying request to /chat/completions in 1.524440 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:18.419767Z"}
{"event": "Retrying request to /chat/completions in 0.451693 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:20.987452Z"}
{"event": "Retrying request to /chat/completions in 0.846434 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:21.450246Z"}
{"event": "Retrying request to /chat/completions in 1.582200 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:22.307897Z"}
{"event": "Retrying request to /chat/completions in 0.422635 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:25.926972Z"}
{"event": "Retrying request to /chat/completions in 0.778712 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:26.352349Z"}
{"event": "Retrying request to /chat/completions in 1.998406 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:27.139142Z"}
{"event": "Retrying request to /chat/completions in 0.491926 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:29.191780Z"}
{"event": "Retrying request to /chat/completions in 0.929373 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:29.689971Z"}
{"event": "Retrying request to /chat/completions in 1.778275 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:30.626833Z"}
{"event": "Retrying request to /chat/completions in 0.445810 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:32.420401Z"}
{"event": "Retrying request to /chat/completions in 0.901824 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:32.876465Z"}
{"event": "Retrying request to /chat/completions in 1.779278 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:33.784869Z"}
{"event": "Retrying request to /chat/completions in 0.463575 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:36.598702Z"}
{"event": "Retrying request to /chat/completions in 0.790225 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:37.073189Z"}
{"event": "Retrying request to /chat/completions in 1.810800 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:37.871377Z"}
{"event": "Retrying request to /chat/completions in 0.462700 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:41.708746Z"}
{"event": "Retrying request to /chat/completions in 0.971685 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:42.181553Z"}
{"event": "Retrying request to /chat/completions in 1.759415 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:49:43.165005Z"}
{"request_id": "f05afd40", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 53, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 47710.75, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:49:45.006208Z"}
{"request_id": "948c2a69", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hu", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:57:04.168392Z"}
{"request_id": "948c2a69", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 34, in chat\n    params = LLMConfigParams(\n             ^^^^^^^^^^^^^^^\nNameError: name 'LLMConfigParams' is not defined", "duration_ms": 4.23, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:57:04.171690Z"}
{"request_id": "c915b71c", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:57:59.740861Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T07:58:00.380436Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T07:58:00.385906Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T07:58:00.613919Z"}
{"event": "Retrying request to /chat/completions in 0.435034 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:01.045217Z"}
{"event": "Retrying request to /chat/completions in 0.768501 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:01.489462Z"}
{"event": "Retrying request to /chat/completions in 1.662755 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:02.266953Z"}
{"event": "Retrying request to /chat/completions in 0.489006 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:03.950329Z"}
{"event": "Retrying request to /chat/completions in 0.762611 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:04.448200Z"}
{"event": "Retrying request to /chat/completions in 1.567425 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:05.222545Z"}
{"event": "Retrying request to /chat/completions in 0.420533 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:07.868375Z"}
{"event": "Retrying request to /chat/completions in 0.767025 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:08.292552Z"}
{"event": "Retrying request to /chat/completions in 1.942987 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:09.078043Z"}
{"event": "Retrying request to /chat/completions in 0.422802 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:13.072269Z"}
{"event": "Retrying request to /chat/completions in 0.991413 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:13.501687Z"}
{"event": "Retrying request to /chat/completions in 1.991979 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:14.499052Z"}
{"event": "Retrying request to /chat/completions in 0.442748 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:16.545733Z"}
{"event": "Retrying request to /chat/completions in 0.931184 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:16.997048Z"}
{"event": "Retrying request to /chat/completions in 1.509268 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:17.937960Z"}
{"event": "Retrying request to /chat/completions in 0.482763 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:19.457371Z"}
{"event": "Retrying request to /chat/completions in 0.836431 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:19.945975Z"}
{"event": "Retrying request to /chat/completions in 1.682666 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:20.808520Z"}
{"event": "Retrying request to /chat/completions in 0.410722 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:23.536629Z"}
{"event": "Retrying request to /chat/completions in 0.909278 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:23.955983Z"}
{"event": "Retrying request to /chat/completions in 1.991694 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:24.874114Z"}
{"event": "Retrying request to /chat/completions in 0.417738 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:28.986012Z"}
{"event": "Retrying request to /chat/completions in 0.849668 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:29.408572Z"}
{"event": "Retrying request to /chat/completions in 1.515172 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:30.264921Z"}
{"event": "Retrying request to /chat/completions in 0.410026 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:31.851509Z"}
{"event": "Retrying request to /chat/completions in 0.830786 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:32.272494Z"}
{"event": "Retrying request to /chat/completions in 1.751106 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:33.112121Z"}
{"event": "Retrying request to /chat/completions in 0.380803 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:34.876604Z"}
{"event": "Retrying request to /chat/completions in 0.791770 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:35.322380Z"}
{"event": "Retrying request to /chat/completions in 1.998180 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:36.122748Z"}
{"event": "Retrying request to /chat/completions in 0.386363 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:39.162229Z"}
{"event": "Retrying request to /chat/completions in 0.788412 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:39.554830Z"}
{"event": "Retrying request to /chat/completions in 1.533052 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:40.350136Z"}
{"event": "Retrying request to /chat/completions in 0.490268 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:43.915357Z"}
{"event": "Retrying request to /chat/completions in 0.999301 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:44.410607Z"}
{"event": "Retrying request to /chat/completions in 1.544520 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T07:58:45.415457Z"}
{"request_id": "c915b71c", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 62, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 47293.86, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T07:58:47.033996Z"}
{"request_id": "09b1fb46", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T08:00:00.162655Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T08:00:00.989697Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T08:00:00.990092Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T08:00:01.169960Z"}
{"event": "Retrying request to /chat/completions in 0.452494 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:01.594713Z"}
{"event": "Retrying request to /chat/completions in 0.917935 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:02.052732Z"}
{"event": "Retrying request to /chat/completions in 1.856552 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:02.980058Z"}
{"event": "Retrying request to /chat/completions in 0.386094 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:04.862300Z"}
{"event": "Retrying request to /chat/completions in 0.946798 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:05.264910Z"}
{"event": "Retrying request to /chat/completions in 1.559408 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:06.220632Z"}
{"event": "Retrying request to /chat/completions in 0.441282 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:08.824651Z"}
{"event": "Retrying request to /chat/completions in 0.817065 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:09.271461Z"}
{"event": "Retrying request to /chat/completions in 1.653440 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:10.100421Z"}
{"event": "Retrying request to /chat/completions in 0.433061 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:13.784950Z"}
{"event": "Retrying request to /chat/completions in 0.834985 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:14.221452Z"}
{"event": "Retrying request to /chat/completions in 1.699291 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:15.063304Z"}
{"event": "Retrying request to /chat/completions in 0.409937 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:16.838937Z"}
{"event": "Retrying request to /chat/completions in 0.827095 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:17.251637Z"}
{"event": "Retrying request to /chat/completions in 1.806429 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:18.087268Z"}
{"event": "Retrying request to /chat/completions in 0.392409 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:19.922705Z"}
{"event": "Retrying request to /chat/completions in 0.785630 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:20.319165Z"}
{"event": "Retrying request to /chat/completions in 1.542386 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:21.114569Z"}
{"event": "Retrying request to /chat/completions in 0.472090 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:23.693182Z"}
{"event": "Retrying request to /chat/completions in 0.967608 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:24.171677Z"}
{"event": "Retrying request to /chat/completions in 1.923654 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:25.163151Z"}
{"event": "Retrying request to /chat/completions in 0.434183 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:29.123674Z"}
{"event": "Retrying request to /chat/completions in 0.927876 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:29.566171Z"}
{"event": "Retrying request to /chat/completions in 1.991426 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:30.503262Z"}
{"event": "Retrying request to /chat/completions in 0.398326 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:32.547226Z"}
{"event": "Retrying request to /chat/completions in 0.912120 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:32.952319Z"}
{"event": "Retrying request to /chat/completions in 1.890347 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:33.869996Z"}
{"event": "Retrying request to /chat/completions in 0.409636 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:35.783136Z"}
{"event": "Retrying request to /chat/completions in 0.821609 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:36.204121Z"}
{"event": "Retrying request to /chat/completions in 1.825404 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:37.044872Z"}
{"event": "Retrying request to /chat/completions in 0.463986 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:39.900210Z"}
{"event": "Retrying request to /chat/completions in 0.814212 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:40.367227Z"}
{"event": "Retrying request to /chat/completions in 1.561977 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:41.185667Z"}
{"event": "Retrying request to /chat/completions in 0.457162 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:44.776876Z"}
{"event": "Retrying request to /chat/completions in 0.974243 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:45.243241Z"}
{"event": "Retrying request to /chat/completions in 1.856422 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:00:46.226660Z"}
{"request_id": "09b1fb46", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 62, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 48001.59, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T08:00:48.163554Z"}
{"request_id": "b5c3872d", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T08:02:13.604599Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T08:02:14.403945Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T08:02:14.577716Z"}
{"event": "Retrying request to /chat/completions in 0.461799 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:15.093876Z"}
{"event": "Retrying request to /chat/completions in 0.977796 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:15.562690Z"}
{"event": "Retrying request to /chat/completions in 1.582051 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:16.547303Z"}
{"event": "Retrying request to /chat/completions in 0.465572 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:18.150364Z"}
{"event": "Retrying request to /chat/completions in 0.953987 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:18.625610Z"}
{"event": "Retrying request to /chat/completions in 1.946611 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:19.587283Z"}
{"event": "Retrying request to /chat/completions in 0.385645 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:22.585024Z"}
{"event": "Retrying request to /chat/completions in 0.939373 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:22.980342Z"}
{"event": "Retrying request to /chat/completions in 1.811511 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:23.925152Z"}
{"event": "Retrying request to /chat/completions in 0.436625 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:27.765143Z"}
{"event": "Retrying request to /chat/completions in 0.918555 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:28.206773Z"}
{"event": "Retrying request to /chat/completions in 1.788616 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:29.130074Z"}
{"event": "Retrying request to /chat/completions in 0.495078 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:30.972938Z"}
{"event": "Retrying request to /chat/completions in 0.885807 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:31.480086Z"}
{"event": "Retrying request to /chat/completions in 1.845259 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:32.375062Z"}
{"event": "Retrying request to /chat/completions in 0.432859 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:34.229844Z"}
{"event": "Retrying request to /chat/completions in 0.769180 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:34.668740Z"}
{"event": "Retrying request to /chat/completions in 1.703797 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:35.444968Z"}
{"event": "Retrying request to /chat/completions in 0.449906 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:38.177704Z"}
{"event": "Retrying request to /chat/completions in 0.881068 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:38.636742Z"}
{"event": "Retrying request to /chat/completions in 1.932833 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:39.524656Z"}
{"event": "Retrying request to /chat/completions in 0.455681 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:43.483949Z"}
{"event": "Retrying request to /chat/completions in 0.804909 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:43.948618Z"}
{"event": "Retrying request to /chat/completions in 1.507793 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:44.760527Z"}
{"event": "Retrying request to /chat/completions in 0.440843 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:46.328084Z"}
{"event": "Retrying request to /chat/completions in 0.777852 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:46.781683Z"}
{"event": "Retrying request to /chat/completions in 1.786293 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:47.565394Z"}
{"event": "Retrying request to /chat/completions in 0.442233 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:49.381684Z"}
{"event": "Retrying request to /chat/completions in 0.961632 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:49.833568Z"}
{"event": "Retrying request to /chat/completions in 1.672686 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:50.802390Z"}
{"event": "Retrying request to /chat/completions in 0.425690 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:53.510733Z"}
{"event": "Retrying request to /chat/completions in 0.956307 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:53.954274Z"}
{"event": "Retrying request to /chat/completions in 1.809577 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:54.915016Z"}
{"event": "Retrying request to /chat/completions in 0.390766 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:58.813876Z"}
{"event": "Retrying request to /chat/completions in 0.764672 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:59.208653Z"}
{"event": "Retrying request to /chat/completions in 1.905010 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:02:59.982361Z"}
{"request_id": "b5c3872d", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 62, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 48378.55, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T08:03:01.981580Z"}
{"request_id": "3b2d776b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T08:22:23.550804Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T08:22:23.554772Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T08:22:24.110987Z"}
{"event": "Retrying request to /chat/completions in 0.463394 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:24.693384Z"}
{"event": "Retrying request to /chat/completions in 0.837281 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:25.161493Z"}
{"event": "Retrying request to /chat/completions in 1.622701 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:26.008817Z"}
{"event": "Retrying request to /chat/completions in 0.445288 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:27.656113Z"}
{"event": "Retrying request to /chat/completions in 0.906607 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:28.105562Z"}
{"event": "Retrying request to /chat/completions in 1.979793 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:29.017953Z"}
{"event": "Retrying request to /chat/completions in 0.485016 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:32.064175Z"}
{"event": "Retrying request to /chat/completions in 0.821361 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:32.577993Z"}
{"event": "Retrying request to /chat/completions in 1.502092 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:33.409762Z"}
{"event": "Retrying request to /chat/completions in 0.438287 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:37.050936Z"}
{"event": "Retrying request to /chat/completions in 0.850969 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:37.494703Z"}
{"event": "Retrying request to /chat/completions in 1.979106 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:38.353639Z"}
{"event": "Retrying request to /chat/completions in 0.495702 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:40.417491Z"}
{"event": "Retrying request to /chat/completions in 0.844164 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:40.921834Z"}
{"event": "Retrying request to /chat/completions in 1.709540 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:41.776916Z"}
{"event": "Retrying request to /chat/completions in 0.413657 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:43.498869Z"}
{"event": "Retrying request to /chat/completions in 0.804665 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:43.921680Z"}
{"event": "Retrying request to /chat/completions in 1.785043 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:44.730038Z"}
{"event": "Retrying request to /chat/completions in 0.376598 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:47.554715Z"}
{"event": "Retrying request to /chat/completions in 0.898084 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:47.937891Z"}
{"event": "Retrying request to /chat/completions in 1.860750 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:48.846584Z"}
{"event": "Retrying request to /chat/completions in 0.412117 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:52.767833Z"}
{"event": "Retrying request to /chat/completions in 0.938957 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:53.188366Z"}
{"event": "Retrying request to /chat/completions in 1.619040 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:54.136915Z"}
{"event": "Retrying request to /chat/completions in 0.424356 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:55.809424Z"}
{"event": "Retrying request to /chat/completions in 0.830374 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:56.239095Z"}
{"event": "Retrying request to /chat/completions in 1.708295 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:57.084166Z"}
{"event": "Retrying request to /chat/completions in 0.426045 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:58.807240Z"}
{"event": "Retrying request to /chat/completions in 0.814512 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:22:59.241800Z"}
{"event": "Retrying request to /chat/completions in 1.580464 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:23:00.063196Z"}
{"event": "Retrying request to /chat/completions in 0.489693 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:23:02.671432Z"}
{"event": "Retrying request to /chat/completions in 0.760058 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:23:03.168849Z"}
{"event": "Retrying request to /chat/completions in 1.588876 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:23:03.933654Z"}
{"event": "Retrying request to /chat/completions in 0.472985 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:23:07.559939Z"}
{"event": "Retrying request to /chat/completions in 0.797927 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:23:08.038669Z"}
{"event": "Retrying request to /chat/completions in 1.634071 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T08:23:08.840561Z"}
{"request_id": "3b2d776b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 59, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 25, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 47010.5, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T08:23:10.560607Z"}
{"request_id": "bf7c05e1", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T08:55:28.559279Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T08:55:28.564083Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T08:55:29.027112Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T08:55:32.551633Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T08:55:32.552439Z"}
{"request_id": "bf7c05e1", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 3995.01, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T08:55:32.553667Z"}
{"request_id": "9faa54a5", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:07:17.678907Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:07:17.833767Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 2, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:07:17.841188Z"}
{"request_id": "9faa54a5", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 201.99, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:07:17.846370Z"}
{"request_id": "d13d965b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "135"}, "query_params": {}, "body": {"user_input": "what you od?", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:07:23.730672Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:07:23.738708Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:07:24.645346Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T09:07:28.724051Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:07:28.725274Z"}
{"request_id": "d13d965b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 4996.27, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:07:28.725745Z"}
{"request_id": "f1208779", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:13:08.702366Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:13:08.722390Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 4, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:13:08.725684Z"}
{"request_id": "f1208779", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 29.45, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:13:08.727193Z"}
{"request_id": "efc090db", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "147"}, "query_params": {}, "body": {"user_input": "good. can we make songs?", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:13:23.128679Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:13:23.132905Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:13:23.474130Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T09:13:27.144792Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:13:27.145829Z"}
{"request_id": "efc090db", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 4018.38, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:13:27.146153Z"}
{"request_id": "e09980ae", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "150"}, "query_params": {}, "body": {"user_input": "great. do you know chinese?", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:14:21.211531Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:14:21.217666Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T09:14:21.219273Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:14:21.453388Z"}
{"request_id": "e09980ae", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 65, in chat\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 427, in sync_wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 398, in sync_wrapper\n    result = func(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 62, in forward\n    response_prediction = self.generate_response(\n        user_message=user_message,\n    ...<2 lines>...\n        user_intent=intent,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/chain_of_thought.py\", line 37, in forward\n    return self.predict(**kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 125, in __call__\n    inputs = self.format(processed_signature, demos, inputs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 197, in format\n    conversation_history = self.format_conversation_history(\n        signature_without_history,\n        history_field_name,\n        inputs_copy,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 411, in format_conversation_history\n    conversation_history = inputs[history_field_name].messages if history_field_name in inputs else None\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'list' object has no attribute 'messages'", "duration_ms": 2366.2, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:14:23.577156Z"}
{"request_id": "ea536a83", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "143"}, "query_params": {}, "body": {"user_input": "do you know chinese?", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:16:57.842857Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:16:57.844988Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T09:16:57.845368Z"}
{"request_id": "ea536a83", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 55, in chat\n    log.debug(\"Retrieved conversation history\", message_count=len(previous_conversation))\n                                                              ~~~^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: object of type 'History' has no len()", "duration_ms": 4.17, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:16:57.846369Z"}
{"request_id": "1260cb79", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:18:01.801346Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:18:01.805353Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 6, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:18:01.807132Z"}
{"request_id": "1260cb79", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 9.01, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:18:01.807566Z"}
{"request_id": "092d0edd", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "143"}, "query_params": {}, "body": {"user_input": "do you know chinese?", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:18:07.726437Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:18:07.737985Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T09:18:07.739194Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:18:08.045153Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:18:12.023627Z"}
{"request_id": "092d0edd", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 4304.5, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:18:12.025024Z"}
{"request_id": "5423ce80", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:26:25.311151Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:26:25.313564Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 8, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:26:25.315122Z"}
{"request_id": "5423ce80", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 4.72, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:26:25.315576Z"}
{"request_id": "ba42c7c7", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "185"}, "query_params": {}, "body": {"user_input": "do you know to create a good chinese song lyrics? about rythum", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:26:52.369580Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:26:52.381289Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T09:26:52.381721Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:26:52.563099Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:26:57.232513Z"}
{"request_id": "ba42c7c7", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 4864.72, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:26:57.233008Z"}
{"request_id": "ff8b0d18", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:41:11.396771Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:41:11.402884Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 10, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:41:11.405383Z"}
{"request_id": "ff8b0d18", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 10.8, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:41:11.406771Z"}
{"request_id": "6d919370", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "194"}, "query_params": {}, "body": {"user_input": "no about Rhythm. i mean the words Rhythm do need to match with the song", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:41:39.923606Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:41:39.926065Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:41:40.098761Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T09:41:40.107084Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:41:45.732960Z"}
{"request_id": "6d919370", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 5811.25, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:41:45.733563Z"}
{"request_id": "633c74e1", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "186"}, "query_params": {}, "body": {"user_input": "is there any general rules for it? especially for chinese songs", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:43:18.046465Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:43:18.057129Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:43:18.267085Z"}
{"event": "Context error: No active span in current context. Operations that depend on an active span will be skipped. Ensure spans are created with start_as_current_span() or that you're operating within an active span context.", "level": "warning", "logger": "langfuse", "timestamp": "2025-10-05T09:43:24.957342Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:43:24.959655Z"}
{"request_id": "633c74e1", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 6914.96, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:43:24.960813Z"}
{"request_id": "5516b7d9", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "154"}, "query_params": {}, "body": {"user_input": "I am focusing on Cantonese song", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:50:25.167138Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:50:25.170490Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:50:25.434839Z"}
{"request_id": "5516b7d9", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 73, in chat\n    response_content = wrapper_function(\n        user_id = request.user_id,\n    ...<3 lines>...\n         context=page_context\n        )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 427, in sync_wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 398, in sync_wrapper\n    result = func(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 41, in wrapper_function\n    user_id=request.user_id,\n            ^^^^^^^\nNameError: name 'request' is not defined", "duration_ms": 4965.29, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:50:30.131787Z"}
{"request_id": "341b2412", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:50:53.311896Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:50:53.314239Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 14, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:50:53.316260Z"}
{"request_id": "341b2412", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 6.19, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:50:53.317502Z"}
{"request_id": "1d9fb7e9", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "154"}, "query_params": {}, "body": {"user_input": "I am focusing on Cantonese song", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:50:56.200106Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:50:56.202731Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:50:56.363222Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:50:56.483306Z"}
{"request_id": "1d9fb7e9", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 284.48, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:50:56.483614Z"}
{"request_id": "b2f3f2d7", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "192"}, "query_params": {}, "body": {"user_input": "yes but i heard that cantonese lyrics is very different from Mandarin", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:53:49.159381Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:53:49.164365Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:53:49.311038Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:53:53.883734Z"}
{"request_id": "b2f3f2d7", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 4725.59, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:53:53.884313Z"}
{"request_id": "829f3874", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "177"}, "query_params": {}, "body": {"user_input": "so for cantonese song lyric writing any special conern", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:57:06.112770Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:57:06.122531Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:57:06.354323Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:57:13.548559Z"}
{"request_id": "829f3874", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 7438.55, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:57:13.550463Z"}
{"request_id": "305e80f5", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "132"}, "query_params": {}, "body": {"user_input": "thank you", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T09:59:58.306128Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T09:59:58.308447Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T09:59:58.461309Z"}
{"request_id": "305e80f5", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 74, in chat\n    response_content = wrapper_function()\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 427, in sync_wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 398, in sync_wrapper\n    result = func(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 63, in wrapper_function\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 26, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 1360, in exception_type\n    raise litellm.InternalServerError(\n    ...<9 lines>...\n    )\nlitellm.exceptions.InternalServerError: litellm.InternalServerError: GeminiException InternalServerError - Vertex AI has a custom implementation of transform_request. Needs sync + async.", "duration_ms": 9731.48, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T10:00:08.037028Z"}
{"request_id": "0683a1c4", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "132"}, "query_params": {}, "body": {"user_input": "thank you", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T10:01:15.172950Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T10:01:15.177886Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T10:01:15.602816Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T10:01:19.279879Z"}
{"request_id": "0683a1c4", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 4108.2, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T10:01:19.280505Z"}
{"request_id": "85eeaa12", "method": "GET", "path": "/health", "client_host": "127.0.0.1", "headers": {"host": "localhost:3010", "user-agent": "curl/8.7.1", "accept": "*/*"}, "query_params": {}, "body": null, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T12:15:18.781355Z"}
{"request_id": "85eeaa12", "method": "GET", "path": "/health", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 1.32, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T12:15:18.782540Z"}
{"request_id": "aa2252ac", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T12:18:38.995440Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T12:18:39.012794Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 22, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T12:18:39.018398Z"}
{"request_id": "aa2252ac", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 31.13, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T12:18:39.020879Z"}
{"request_id": "e0ceddb9", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T12:18:45.222004Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T12:18:45.225667Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T12:18:45.567893Z"}
{"event": "Retrying request to /chat/completions in 0.495427 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:46.337616Z"}
{"event": "Retrying request to /chat/completions in 0.939462 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:46.839340Z"}
{"event": "Retrying request to /chat/completions in 1.561909 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:47.788654Z"}
{"event": "Retrying request to /chat/completions in 0.454414 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:49.385670Z"}
{"event": "Retrying request to /chat/completions in 0.977186 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:49.847755Z"}
{"event": "Retrying request to /chat/completions in 1.596338 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:50.833927Z"}
{"event": "Retrying request to /chat/completions in 0.492348 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:53.488233Z"}
{"event": "Retrying request to /chat/completions in 0.802138 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:53.988109Z"}
{"event": "Retrying request to /chat/completions in 1.881837 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:54.796630Z"}
{"event": "Retrying request to /chat/completions in 0.376248 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:58.707172Z"}
{"event": "Retrying request to /chat/completions in 0.986412 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:18:59.091357Z"}
{"event": "Retrying request to /chat/completions in 1.630068 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:00.084030Z"}
{"event": "Retrying request to /chat/completions in 0.491659 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:01.793216Z"}
{"event": "Retrying request to /chat/completions in 0.983289 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:02.292603Z"}
{"event": "Retrying request to /chat/completions in 1.523050 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:03.280825Z"}
{"event": "Retrying request to /chat/completions in 0.458497 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:04.822405Z"}
{"event": "Retrying request to /chat/completions in 0.854909 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:05.364958Z"}
{"event": "Retrying request to /chat/completions in 1.904517 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:06.230871Z"}
{"event": "Retrying request to /chat/completions in 0.405774 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:09.188781Z"}
{"event": "Retrying request to /chat/completions in 0.783695 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:09.608971Z"}
{"event": "Retrying request to /chat/completions in 1.600425 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:10.399518Z"}
{"event": "Retrying request to /chat/completions in 0.394769 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:14.042499Z"}
{"event": "Retrying request to /chat/completions in 0.895124 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:14.447207Z"}
{"event": "Retrying request to /chat/completions in 1.683016 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:15.353747Z"}
{"event": "Retrying request to /chat/completions in 0.419109 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:17.101432Z"}
{"event": "Retrying request to /chat/completions in 0.950080 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:17.529617Z"}
{"event": "Retrying request to /chat/completions in 1.830221 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:18.486233Z"}
{"event": "Retrying request to /chat/completions in 0.488319 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:20.350588Z"}
{"event": "Retrying request to /chat/completions in 0.978971 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:20.849438Z"}
{"event": "Retrying request to /chat/completions in 1.873728 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:21.832037Z"}
{"event": "Retrying request to /chat/completions in 0.459532 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:24.748491Z"}
{"event": "Retrying request to /chat/completions in 0.757175 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:25.212831Z"}
{"event": "Retrying request to /chat/completions in 1.962007 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:25.974711Z"}
{"event": "Retrying request to /chat/completions in 0.422086 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:29.958785Z"}
{"event": "Retrying request to /chat/completions in 0.886144 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:30.384334Z"}
{"event": "Retrying request to /chat/completions in 1.860457 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:19:31.278435Z"}
{"request_id": "e0ceddb9", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 74, in chat\n    response_content = wrapper_function()\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 427, in sync_wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 398, in sync_wrapper\n    result = func(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 63, in wrapper_function\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 26, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 48007.82, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T12:19:33.226122Z"}
{"request_id": "4eea44a9", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T12:21:15.564321Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T12:21:15.568303Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T12:21:16.088800Z"}
{"event": "Retrying request to /chat/completions in 0.396168 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:16.571351Z"}
{"event": "Retrying request to /chat/completions in 0.830299 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:16.975019Z"}
{"event": "Retrying request to /chat/completions in 1.501762 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:17.815412Z"}
{"event": "Retrying request to /chat/completions in 0.443979 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:19.372404Z"}
{"event": "Retrying request to /chat/completions in 0.932730 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:19.832822Z"}
{"event": "Retrying request to /chat/completions in 1.604064 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:20.778417Z"}
{"event": "Retrying request to /chat/completions in 0.496051 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:23.437783Z"}
{"event": "Retrying request to /chat/completions in 0.777914 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:23.939448Z"}
{"event": "Retrying request to /chat/completions in 1.546590 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:24.723246Z"}
{"event": "Retrying request to /chat/completions in 0.443565 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:28.299049Z"}
{"event": "Retrying request to /chat/completions in 0.916777 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:28.749710Z"}
{"event": "Retrying request to /chat/completions in 1.931573 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:29.671567Z"}
{"event": "Retrying request to /chat/completions in 0.471142 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:31.677324Z"}
{"event": "Retrying request to /chat/completions in 0.933999 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:32.151623Z"}
{"event": "Retrying request to /chat/completions in 1.573244 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:33.090473Z"}
{"event": "Retrying request to /chat/completions in 0.398334 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:34.684508Z"}
{"event": "Retrying request to /chat/completions in 0.917485 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:35.086637Z"}
{"event": "Retrying request to /chat/completions in 1.874263 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:36.007149Z"}
{"event": "Retrying request to /chat/completions in 0.401541 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:38.925096Z"}
{"event": "Retrying request to /chat/completions in 0.947714 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:39.329488Z"}
{"event": "Retrying request to /chat/completions in 1.683804 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:40.285272Z"}
{"event": "Retrying request to /chat/completions in 0.427988 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:44.015337Z"}
{"event": "Retrying request to /chat/completions in 0.857287 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:44.451231Z"}
{"event": "Retrying request to /chat/completions in 1.649774 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:45.332480Z"}
{"event": "Retrying request to /chat/completions in 0.406569 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:47.047924Z"}
{"event": "Retrying request to /chat/completions in 0.963544 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:47.458002Z"}
{"event": "Retrying request to /chat/completions in 1.956659 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:48.426747Z"}
{"event": "Retrying request to /chat/completions in 0.437408 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:50.423016Z"}
{"event": "Retrying request to /chat/completions in 0.978020 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:50.868253Z"}
{"event": "Retrying request to /chat/completions in 1.620326 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:51.853161Z"}
{"event": "Retrying request to /chat/completions in 0.433636 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:54.521622Z"}
{"event": "Retrying request to /chat/completions in 0.789270 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:54.961527Z"}
{"event": "Retrying request to /chat/completions in 1.912776 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:55.760808Z"}
{"event": "Retrying request to /chat/completions in 0.398029 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:21:59.712104Z"}
{"event": "Retrying request to /chat/completions in 0.969394 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:22:00.118274Z"}
{"event": "Retrying request to /chat/completions in 1.979780 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T12:22:01.099708Z"}
{"request_id": "4eea44a9", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "exception": "Traceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 151, in call_next\n    message = await recv_stream.receive()\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/streams/memory.py\", line 126, in receive\n    raise EndOfStream from None\nanyio.EndOfStream\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/middleware/logging_middleware.py\", line 48, in dispatch\n    response = await call_next(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 159, in call_next\n    raise app_exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/base.py\", line 144, in coro\n    await self.app(scope, receive_or_disconnect, send_no_error)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/middleware/exceptions.py\", line 63, in __call__\n    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/middleware/asyncexitstack.py\", line 18, in __call__\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 716, in __call__\n    await self.middleware_stack(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 736, in app\n    await route.handle(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/routing.py\", line 290, in handle\n    await self.app(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 123, in app\n    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 53, in wrapped_app\n    raise exc\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/_exception_handler.py\", line 42, in wrapped_app\n    await app(scope, receive, sender)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 109, in app\n    response = await f(request)\n               ^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 387, in app\n    raw_response = await run_endpoint_function(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/fastapi/routing.py\", line 290, in run_endpoint_function\n    return await run_in_threadpool(dependant.call, **values)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/starlette/concurrency.py\", line 38, in run_in_threadpool\n    return await anyio.to_thread.run_sync(func)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/to_thread.py\", line 56, in run_sync\n    return await get_async_backend().run_sync_in_worker_thread(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 2485, in run_sync_in_worker_thread\n    return await future\n           ^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/anyio/_backends/_asyncio.py\", line 976, in run\n    result = context.run(func, *args)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 74, in chat\n    response_content = wrapper_function()\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 427, in sync_wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/langfuse/_client/observe.py\", line 398, in sync_wrapper\n    result = func(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/api/main.py\", line 63, in wrapper_function\n    response_content = orchestrator(user_message=request.user_input,\n                                    previous_conversation=previous_conversation,\n                                    page_context=page_context)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/src/app/llm/modules/ConversationOrchestrator.py\", line 26, in forward\n    intent_prediction = self.determine_intent(\n        user_message=user_message,\n        previous_conversation=previous_conversation,\n        page_context=page_context\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 103, in __call__\n    return super().__call__(**kwargs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 567, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/primitives/module.py\", line 78, in __call__\n    return self.forward(*args, **kwargs)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 417, in __call__\n    prediction = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/predict/predict.py\", line 192, in forward\n    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 746, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/adapters/base.py\", line 127, in __call__\n    outputs = lm(messages=inputs, **lm_kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/openinference/instrumentation/dspy/__init__.py\", line 297, in __call__\n    response = wrapped(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n    return fn(instance, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/base_lm.py\", line 85, in __call__\n    response = self.forward(prompt=prompt, messages=messages, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 147, in forward\n    results = completion(\n        request=dict(model=self.model, messages=messages, **kwargs),\n        num_retries=self.num_retries,\n        cache=litellm_cache_args,\n    )\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/cache.py\", line 235, in sync_wrapper\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/dspy/clients/lm.py\", line 336, in litellm_completion\n    return litellm.completion(\n           ~~~~~~~~~~~~~~~~~~^\n        cache=cache,\n        ^^^^^^^^^^^^\n    ...<2 lines>...\n        **request,\n        ^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1332, in wrapper\n    return litellm.completion_with_retries(*args, **kwargs)\n           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3739, in completion_with_retries\n    return retryer(original_function, *args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 477, in __call__\n    do = self.iter(retry_state=retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 378, in iter\n    result = action(retry_state)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 420, in exc_check\n    raise retry_exc.reraise()\n          ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 187, in reraise\n    raise self.last_attempt.result()\n          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 449, in result\n    return self.__get_result()\n           ~~~~~~~~~~~~~~~~~^^\n  File \"/Users/xavierau/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py\", line 401, in __get_result\n    raise self._exception\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/tenacity/__init__.py\", line 480, in __call__\n    result = fn(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1352, in wrapper\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/utils.py\", line 1227, in wrapper\n    result = original_function(*args, **kwargs)\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/main.py\", line 3701, in completion\n    raise exception_type(\n          ~~~~~~~~~~~~~~^\n        model=model,\n        ^^^^^^^^^^^^\n    ...<3 lines>...\n        extra_kwargs=kwargs,\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2273, in exception_type\n    raise e\n  File \"/Users/xavierau/Code/python/showeasy_chatbot/.venv/lib/python3.13/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py\", line 2038, in exception_type\n    raise APIConnectionError(\n    ...<4 lines>...\n    )\nlitellm.exceptions.APIConnectionError: litellm.APIConnectionError: AzureException APIConnectionError - Connection error.", "duration_ms": 47590.17, "event": "Request failed", "level": "error", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T12:22:03.153888Z"}
{"request_id": "a3a6fc3c", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "135"}, "query_params": {}, "body": {"user_input": "any concert?", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:09:37.499048Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:09:37.501690Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:09:37.791061Z"}
{"event": "Retrying request to /chat/completions in 0.387827 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:38.278426Z"}
{"event": "Retrying request to /chat/completions in 0.816156 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:38.671507Z"}
{"event": "Retrying request to /chat/completions in 1.942860 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:39.492843Z"}
{"event": "Retrying request to /chat/completions in 0.494259 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:41.470429Z"}
{"event": "Retrying request to /chat/completions in 0.977255 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:41.978022Z"}
{"event": "Retrying request to /chat/completions in 1.784905 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:42.967128Z"}
{"event": "Retrying request to /chat/completions in 0.487638 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:45.813175Z"}
{"event": "Retrying request to /chat/completions in 0.823097 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:46.307861Z"}
{"event": "Retrying request to /chat/completions in 1.996803 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:47.142520Z"}
{"event": "Retrying request to /chat/completions in 0.477118 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:51.195222Z"}
{"event": "Retrying request to /chat/completions in 0.810700 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:51.680548Z"}
{"event": "Retrying request to /chat/completions in 1.527345 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:52.497463Z"}
{"event": "Retrying request to /chat/completions in 0.439957 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:54.090050Z"}
{"event": "Retrying request to /chat/completions in 0.830897 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:54.533198Z"}
{"event": "Retrying request to /chat/completions in 1.961121 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:55.367755Z"}
{"event": "Retrying request to /chat/completions in 0.499913 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:57.344600Z"}
{"event": "Retrying request to /chat/completions in 0.820801 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:57.853078Z"}
{"event": "Retrying request to /chat/completions in 1.949743 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:09:58.684441Z"}
{"event": "Retrying request to /chat/completions in 0.445214 seconds", "level": "info", "logger": "openai._base_client", "timestamp": "2025-10-05T13:10:01.672625Z"}
{"request_id": "cc513c6b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "135"}, "query_params": {}, "body": {"user_input": "any concert?", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:11.520076Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:10:11.523302Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:10:11.862569Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:10:13.731396Z"}
{"request_id": "cc513c6b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 2220.77, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:13.740505Z"}
{"request_id": "b8e13adc", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "136"}, "query_params": {}, "body": {"user_input": "in west coast", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:23.621006Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:10:23.623112Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:10:23.882585Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:10:25.749987Z"}
{"request_id": "b8e13adc", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 2130.28, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:25.750471Z"}
{"request_id": "e1f10f13", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "69"}, "query_params": {}, "body": {"user_input": "", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:32.318554Z"}
{"request_id": "e1f10f13", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 8.53, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:32.324327Z"}
{"request_id": "7a52e4e4", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "72"}, "query_params": {}, "body": {"user_input": "123", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:32.449626Z"}
{"request_id": "7a52e4e4", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 0.77, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:32.450276Z"}
{"request_id": "ef2ef00c", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "69"}, "query_params": {}, "body": {"user_input": "", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:32.466665Z"}
{"request_id": "ef2ef00c", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 0.88, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:32.467458Z"}
{"request_id": "b22349f8", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "1070"}, "query_params": {}, "body": {"user_input": "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:32.489968Z"}
{"request_id": "b22349f8", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 1.24, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:10:32.491114Z"}
{"request_id": "ceb120a1", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "69"}, "query_params": {}, "body": {"user_input": "", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:11:14.590592Z"}
{"request_id": "ceb120a1", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 5.72, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:11:14.595262Z"}
{"request_id": "f0472b8d", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "72"}, "query_params": {}, "body": {"user_input": "123", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:11:14.658724Z"}
{"request_id": "f0472b8d", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 0.63, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:11:14.659278Z"}
{"request_id": "bb976ea2", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "69"}, "query_params": {}, "body": {"user_input": "", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:11:14.671259Z"}
{"request_id": "bb976ea2", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 0.66, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:11:14.671832Z"}
{"request_id": "c0b342b0", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "1070"}, "query_params": {}, "body": {"user_input": "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:11:14.690024Z"}
{"request_id": "c0b342b0", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 1.79, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:11:14.691682Z"}
{"request_id": "06c52b44", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "69"}, "query_params": {}, "body": {"user_input": "", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:01.857147Z"}
{"request_id": "06c52b44", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 4.06, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:01.860451Z"}
{"request_id": "62f716e5", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "72"}, "query_params": {}, "body": {"user_input": "123", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:01.992151Z"}
{"request_id": "62f716e5", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 2.04, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:01.994105Z"}
{"request_id": "fa61c3be", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "69"}, "query_params": {}, "body": {"user_input": "", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:02.019939Z"}
{"request_id": "fa61c3be", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 0.96, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:02.020798Z"}
{"request_id": "f15da3e3", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "1070"}, "query_params": {}, "body": {"user_input": "aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "user_id": null, "session_id": null, "current_url": null}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:02.039687Z"}
{"request_id": "f15da3e3", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 0.8, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:02.040404Z"}
{"request_id": "ee0b66a6", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "125"}, "query_params": {}, "body": {"user_input": "sf", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:06.963249Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:06.975337Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:12:07.156071Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:08.757564Z"}
{"request_id": "ee0b66a6", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 1798.89, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:08.759283Z"}
{"request_id": "6f3d4759", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "130"}, "query_params": {}, "body": {"user_input": "concert", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:22.416261Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:22.422169Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:12:22.938571Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:25.111777Z"}
{"request_id": "6f3d4759", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 2697.74, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:25.112867Z"}
{"request_id": "9acf53ef", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "126"}, "query_params": {}, "body": {"user_input": "any", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:34.115042Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:34.129109Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:12:34.322650Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:35.627161Z"}
{"request_id": "9acf53ef", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 1515.11, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:35.628975Z"}
{"request_id": "b31952af", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "128"}, "query_params": {}, "body": {"user_input": "music", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:46.079329Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:46.082329Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:12:46.441157Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:48.445117Z"}
{"request_id": "b31952af", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 2370.33, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:48.445740Z"}
{"request_id": "7c38636e", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "132"}, "query_params": {}, "body": {"user_input": "pop music", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:12:53.764654Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:12:53.766514Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:12:54.009504Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:13:01.101404Z"}
{"request_id": "7c38636e", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 7341.27, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:13:01.105416Z"}
{"request_id": "08743a5e", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:19:34.713414Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:19:34.718733Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 0, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:19:34.719761Z"}
{"request_id": "08743a5e", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 9.13, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:19:34.722194Z"}
{"request_id": "33cac714", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "45"}, "query_params": {}, "body": {"session_id": "session-1759550155248-rouwgf"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:19:43.528426Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:19:43.531024Z"}
{"session_id": "session-***uwgf", "endpoint": "/chat/messages", "message_count": 0, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:19:43.531290Z"}
{"request_id": "33cac714", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 4.23, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:19:43.531576Z"}
{"request_id": "49a0a732", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "44"}, "query_params": {}, "body": {"session_id": "session-1759670387652-srsei"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:19:47.708867Z"}
{"session_id": "session-***rsei", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:19:47.711428Z"}
{"session_id": "session-***rsei", "endpoint": "/chat/messages", "message_count": 0, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:19:47.711841Z"}
{"request_id": "49a0a732", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 3.69, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:19:47.712244Z"}
{"request_id": "52b812d1", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "148"}, "query_params": {}, "body": {"user_input": "hi do you have any concert", "user_id": null, "session_id": "session-1759670387652-srsei", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:19:57.528477Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:19:57.531557Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:19:57.688160Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:20:04.158728Z"}
{"request_id": "52b812d1", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 6640.68, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:20:04.159831Z"}
{"request_id": "c7d77898", "method": "GET", "path": "/health", "client_host": "127.0.0.1", "headers": {"host": "localhost:3010", "user-agent": "curl/8.7.1", "accept": "*/*"}, "query_params": {}, "body": null, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:48:21.182095Z"}
{"request_id": "c7d77898", "method": "GET", "path": "/health", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 2.71, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:48:21.184181Z"}
{"request_id": "eed3fbaa", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "134"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/events/1"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:50:01.793392Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/events/1", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:50:01.798494Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:50:02.963034Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:50:05.391752Z"}
{"request_id": "eed3fbaa", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 3609.18, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:50:05.392444Z"}
{"request_id": "00e76969", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "151"}, "query_params": {}, "body": {"user_input": "any musical concert", "user_id": null, "session_id": "session-1759550155248-rouwgf", "current_url": "https://eventplatform.test/events/1"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:50:14.569002Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/events/1", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:50:14.572114Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T13:50:14.788067Z"}
{"session_id": "session-***uwgf", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T13:50:21.814742Z"}
{"request_id": "00e76969", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 7249.35, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T13:50:21.817581Z"}
{"request_id": "5c694af0", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "44"}, "query_params": {}, "body": {"session_id": "session-1759670387652-srsei"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:20:32.869218Z"}
{"session_id": "session-***rsei", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:20:32.877083Z"}
{"session_id": "session-***rsei", "endpoint": "/chat/messages", "message_count": 0, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:20:32.878119Z"}
{"request_id": "5c694af0", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 12.16, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:20:32.879163Z"}
{"request_id": "5d21a90b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "124"}, "query_params": {}, "body": {"user_input": "hi", "user_id": null, "session_id": "session-1759670387652-srsei", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:20:35.914825Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:20:35.916909Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T14:20:36.142188Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:20:36.374788Z"}
{"request_id": "5d21a90b", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 462.39, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:20:36.375129Z"}
{"request_id": "8e9f6563", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "142"}, "query_params": {}, "body": {"user_input": "any musical concert?", "user_id": null, "session_id": "session-1759670387652-srsei", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:20:47.975284Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:20:47.981425Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T14:20:48.163944Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:21:00.486148Z"}
{"request_id": "8e9f6563", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 12518.18, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:21:00.492821Z"}
{"request_id": "c35e7562", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "localhost:3010", "user-agent": "curl/8.7.1", "accept": "*/*", "content-type": "application/json", "content-length": "35"}, "query_params": {}, "body": {"message": "find musical concert"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:23:22.548745Z"}
{"request_id": "c35e7562", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 422, "duration_ms": 11.42, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:23:22.557547Z"}
{"request_id": "f7ffbff4", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "localhost:3010", "user-agent": "curl/8.7.1", "accept": "*/*", "content-type": "application/json", "content-length": "116"}, "query_params": {}, "body": {"user_input": "find musical concert", "user_id": "test", "session_id": "test123", "current_url": "http://test.com"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:23:32.451778Z"}
{"session_id": "***", "user_id": "***", "endpoint": "/chat", "current_url": "http://test.com", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:23:32.455088Z"}
{"session_id": "***", "user_id": "***", "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:23:46.738451Z"}
{"request_id": "f7ffbff4", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 14288.5, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:23:46.739223Z"}
{"request_id": "3375424a", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "147"}, "query_params": {}, "body": {"user_input": "how about art exhibition?", "user_id": null, "session_id": "session-1759670387652-srsei", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:31:28.896527Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:31:28.900034Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T14:31:29.189420Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:31:47.943659Z"}
{"request_id": "3375424a", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 19050.55, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:31:47.945141Z"}
{"request_id": "d1944220", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "145"}, "query_params": {}, "body": {"user_input": "how about sport events?", "user_id": null, "session_id": "session-1759670387652-srsei", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:38:24.095295Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:38:24.098630Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T14:38:24.322587Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:38:33.099179Z"}
{"request_id": "d1944220", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 9006.69, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:38:33.101369Z"}
{"request_id": "d9c2180d", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "141"}, "query_params": {}, "body": {"user_input": "any art exhibition?", "user_id": null, "session_id": "session-1759670387652-srsei", "current_url": "https://eventplatform.test/"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:39:01.593561Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "current_url": "https://eventplatform.test/", "event": "Chat request started", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:39:01.597298Z"}
{"event": "ruthless removal did not work. ", "level": "info", "logger": "readability.readability", "timestamp": "2025-10-05T14:39:01.857206Z"}
{"session_id": "session-***rsei", "user_id": null, "endpoint": "/chat", "event": "Chat request completed successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:39:10.508666Z"}
{"request_id": "d9c2180d", "method": "POST", "path": "/chat", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 8917.17, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:39:10.509974Z"}
{"request_id": "b7c43c9b", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "44"}, "query_params": {}, "body": {"session_id": "session-1759670387652-srsei"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:39:17.403106Z"}
{"session_id": "session-***rsei", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:39:17.406395Z"}
{"session_id": "session-***rsei", "endpoint": "/chat/messages", "message_count": 2, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:39:17.407350Z"}
{"request_id": "b7c43c9b", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 5.85, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:39:17.407825Z"}
{"request_id": "a1965086", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "headers": {"host": "127.0.0.1:3010", "user-agent": "GuzzleHttp/7", "content-type": "application/json", "content-length": "44"}, "query_params": {}, "body": {"session_id": "session-1759670387652-srsei"}, "event": "Request received", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:39:30.956815Z"}
{"session_id": "session-***rsei", "endpoint": "/chat/messages", "event": "Retrieving messages", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:39:30.959658Z"}
{"session_id": "session-***rsei", "endpoint": "/chat/messages", "message_count": 2, "event": "Messages retrieved successfully", "level": "info", "logger": "app.api.main", "timestamp": "2025-10-05T14:39:30.961092Z"}
{"request_id": "a1965086", "method": "POST", "path": "/chat/messages", "client_host": "127.0.0.1", "status_code": 200, "duration_ms": 5.62, "event": "Request completed", "level": "info", "logger": "app.middleware.logging_middleware", "timestamp": "2025-10-05T14:39:30.961596Z"}
